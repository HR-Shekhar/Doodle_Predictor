{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4acb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa388e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ('./data/')\n",
    "class_names = [\"airplane\", \"apple\", \"bat\", \"cat\", \"circle\", \"clock\", \"cloud\",\n",
    "               \"crown\", \"diamond\", \"dog\", \"donut\", \"face\", \"fish\", \"hexagon\",\n",
    "                \"hot_dog\", \"lightning\", \"mountain\", \"river\", \"skull\",\n",
    "                \"smiley_face\", \"square\", \"star\", \"sun\", \"t-shirt\", \"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f4ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_class = 5000\n",
    "\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a12996",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, class_name in enumerate(class_names):\n",
    "    # Create the path to the .npy file (e.g., './data/apple.npy')\n",
    "    file_path = os.path.join(data_dir, f\"{class_name}.npy\")\n",
    "\n",
    "    # Load the .npy file → shape: (2000, 28, 28)\n",
    "    data = np.load(file_path)\n",
    "\n",
    "    X.append(data)\n",
    "\n",
    "    # Add labels to y → [label, label, label, ..., label] (length = number of samples)\n",
    "    y.append(np.full((data.shape[0]), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591e25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all image arrays vertically → final shape: (total_samples, 28, 28)\n",
    "X = np.vstack(X)\n",
    "\n",
    "# Stack all label arrays horizontally → final shape: (total_samples,)\n",
    "y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93e403",
   "metadata": {},
   "source": [
    "### Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8295fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize pixel values to range 0–1 (from 0–255)\n",
    "X = X.astype('float32') / 255.0\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958befe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each image from 28x28 → 784 for dense layers\n",
    "X = X.reshape(X.shape[0], -1)  # shape becomes (total_samples, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabbc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_, y_train, y_ = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n",
    "# `stratify=y` ensures equal class distribution in both training and validation sets.\n",
    "\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_,y_, test_size=0.5, random_state=42, stratify=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7f458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(784,), name=\"input_vector\"),\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(class_names), activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "574fe9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b06072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.9686\n",
      "Epoch 2/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.3993\n",
      "Epoch 3/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.3424\n",
      "Epoch 4/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.3007\n",
      "Epoch 5/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2860\n",
      "Epoch 6/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2829\n",
      "Epoch 7/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2771\n",
      "Epoch 8/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2667\n",
      "Epoch 9/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2596\n",
      "Epoch 10/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2571\n",
      "Epoch 11/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.2633\n",
      "Epoch 12/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2606\n",
      "Epoch 13/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2514\n",
      "Epoch 14/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.2477\n",
      "Epoch 15/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2517\n",
      "Epoch 16/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2461\n",
      "Epoch 17/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2468\n",
      "Epoch 18/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2406\n",
      "Epoch 19/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2402\n",
      "Epoch 20/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2395\n",
      "Epoch 21/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2429\n",
      "Epoch 22/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2464\n",
      "Epoch 23/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2434\n",
      "Epoch 24/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2494\n",
      "Epoch 25/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2480\n",
      "Epoch 26/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2417\n",
      "Epoch 27/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2421\n",
      "Epoch 28/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2372\n",
      "Epoch 29/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2353\n",
      "Epoch 30/30\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.2458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x246a77ca780>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf84eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_cv_pred_probs = model.predict(X_cv)   #predict probability for each label\n",
    "y_cv_pred = np.argmax(y_cv_pred_probs, axis=1)  # selects the label with maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabe316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,y_cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47139c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "0.7604\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_probs = model.predict(X_test) \n",
    "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
    "print(accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ffe07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"doodle_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877935fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
